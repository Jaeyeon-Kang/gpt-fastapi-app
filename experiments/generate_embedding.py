# generate_embedding.py
import os, faiss, numpy as np
from openai import OpenAI
from dotenv import load_dotenv
from pathlib import Path

# â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TEXT_PATH   = "data/text_chunks.txt"
INDEX_PATH  = "data/index.faiss"
EMBED_MODEL = "text-embedding-3-small"
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def load_chunks(path=TEXT_PATH):
    with open(path, encoding="utf-8") as f:
        return [c.strip() for c in f.read().split("\n\n") if c.strip()]

def build_index(chunks):
    embeds = []
    for i, chunk in enumerate(chunks, 1):
        print(f"ðŸ”¹ [{i}/{len(chunks)}] embedding: {chunk[:30]}â€¦")
        emb = client.embeddings.create(input=chunk, model=EMBED_MODEL).data[0].embedding
        embeds.append(emb)

    xb   = np.array(embeds, dtype="float32")
    dim  = xb.shape[1]
    idx  = faiss.IndexFlatL2(dim)
    idx.add(xb)
    Path(INDEX_PATH).parent.mkdir(parents=True, exist_ok=True)
    faiss.write_index(idx, INDEX_PATH)
    print(f"âœ… wrote {len(chunks)} vectors â†’ {INDEX_PATH}")

if __name__ == "__main__":
    build_index(load_chunks())