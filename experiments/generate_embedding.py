# generate_embedding.py

import os
import openai
import faiss
import numpy as np
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (OPENAI_API_KEY)
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# íŒŒì¼ ê²½ë¡œ
TEXT_PATH = "data/text_chunks.txt"
INDEX_PATH = "data/index.faiss"
EMBEDDING_MODEL = "text-embedding-3-small"

def get_text_chunks(path):
    with open(path, "r", encoding="utf-8") as f:
        text = f.read()
    # ë¬¸ë‹¨ êµ¬ë¶„ ê¸°ì¤€: ì œëª© ì œì™¸, ìˆ«ì. ë˜ëŠ” \n\në¡œ ë¶„ë¦¬ ê°€ëŠ¥
    return [chunk.strip() for chunk in text.split("\n\n") if chunk.strip()]

def get_embedding(text):
    response = openai.embeddings.create(
        input=text,
        model=EMBEDDING_MODEL
    )
    return response.data[0].embedding

def main():
    chunks = get_text_chunks(TEXT_PATH)
    print(f"âœ… ë¬¸ë‹¨ ìˆ˜: {len(chunks)}")

    embeddings = []
    for i, chunk in enumerate(chunks):
        print(f"ğŸ”¹ [{i+1}] ì„ë² ë”© ì¤‘: {chunk[:30]}...")
        embedding = get_embedding(chunk)
        embeddings.append(embedding)

    # numpy ë°°ì—´ë¡œ ë³€í™˜
    embedding_matrix = np.array(embeddings).astype("float32")

    # FAISS ì¸ë±ìŠ¤ ìƒì„±
    dimension = len(embedding_matrix[0])
    index = faiss.IndexFlatL2(dimension)
    index.add(embedding_matrix)
    faiss.write_index(index, INDEX_PATH)

    print(f"\nâœ… FAISS ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: {INDEX_PATH}")

if __name__ == "__main__":
    main()
