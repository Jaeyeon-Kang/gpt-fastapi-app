# generate_embedding.py
import os, faiss, numpy as np
from openai import OpenAI
from dotenv import load_dotenv
from pathlib import Path
from utils.data_loader import load_chunks

# â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
INDEX_PATH  = "data/index.faiss"
EMBED_MODEL = "text-embedding-3-small"
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def build_index(chunks):
    if not chunks:
        print("ğŸ¤·â€â™€ï¸ ì¸ë±ìŠ¤ë¥¼ ë§Œë“¤ í…ìŠ¤íŠ¸ ì¡°ê°ì´ ì—†ìŠµë‹ˆë‹¤. data/text_chunks.txt íŒŒì¼ì´ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”.")
        # ë¹„ì–´ìˆëŠ” index.faiss íŒŒì¼ì„ ë§Œë“¤ê±°ë‚˜ ê·¸ëƒ¥ ë¦¬í„´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # ì—¬ê¸°ì„œëŠ” ê·¸ëƒ¥ ë¦¬í„´í•˜ì—¬ ì•„ë¬´ ì‘ì—…ë„ í•˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.
        return

    embeds = []
    for i, chunk in enumerate(chunks, 1):
        print(f"ğŸ”¹ [{i}/{len(chunks)}] embedding: {chunk[:30]}â€¦")
        emb = client.embeddings.create(input=chunk, model=EMBED_MODEL).data[0].embedding
        embeds.append(emb)

    xb   = np.array(embeds, dtype="float32")
    dim  = xb.shape[1]
    idx  = faiss.IndexFlatL2(dim)
    idx.add(xb)  # type: ignore
    Path(INDEX_PATH).parent.mkdir(parents=True, exist_ok=True)
    faiss.write_index(idx, INDEX_PATH)
    print(f"âœ… wrote {len(chunks)} vectors â†’ {INDEX_PATH}")

if __name__ == "__main__":
    chunks_to_build = load_chunks()
    build_index(chunks_to_build)