# search_test.py (ìˆ˜ì •ëœ ë²„ì „)

import os
import openai
import faiss
import csv
import numpy as np
from dotenv import load_dotenv
from datetime import datetime

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# ê²½ë¡œ ì„¤ì •
INDEX_PATH = "data/index.faiss"
TEXT_PATH = "data/text_chunks.txt"
LOG_PATH = "logs/search_logs.csv"
EMBEDDING_MODEL = "text-embedding-3-small"

# ë¬¸ë‹¨ ë¶ˆëŸ¬ì˜¤ê¸°
def load_text_chunks(path):
    with open(path, "r", encoding="utf-8") as f:
        return [chunk.strip() for chunk in f.read().split("\n\n") if chunk.strip()]

# ì„ë² ë”©
def embed_text(text):
    response = openai.embeddings.create(
        input=text,
        model=EMBEDDING_MODEL
    )
    return np.array(response.data[0].embedding).astype("float32").reshape(1, -1)

def generate_gpt_answer(question, top_chunks):
    system_prompt = "ë‹¤ìŒ ë¬¸ë‹¨ë“¤ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."
    context = "\n\n".join(top_chunks)

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"{context}\n\nì§ˆë¬¸: {question}"}
    ]

    response = openai.chat.completions.create(
        model="gpt-4",
        messages=messages,
        temperature=0.7
    )
    return response.choices[0].message.content.strip()

# ê²€ìƒ‰ + ë¡œê·¸ ì €ì¥
def search_similar(question, top_k=3):
    index = faiss.read_index(INDEX_PATH)
    chunks = load_text_chunks(TEXT_PATH)
    query_vec = embed_text(question)
    
    D, I = index.search(query_vec, top_k)
    top_chunks = [chunks [idx] for idx in I[0]]
    gpt_answer = generate_gpt_answer(question, top_chunks)

    print(f"\nğŸ” ì§ˆë¬¸: {question}")
    print(f"ğŸ“ Top-{top_k} ìœ ì‚¬ ë¬¸ë‹¨ ê²°ê³¼:\n")
    print("\nğŸ§  GPT ì‘ë‹µ:")
    print(gpt_answer)
    print(query_vec.shape)  # â†’ (1, 1536)
    print(query_vec[0][:5])  # â†’ ì²« 5ì°¨ì›ë§Œ ì¶œë ¥í•´ë³´ê¸°


    # ë¡œê·¸ ë°ì´í„° êµ¬ì„±
    log_entries = []
    timestamp = datetime.now().isoformat()

    for rank, (idx, score) in enumerate(zip(I[0], D[0]), 1):
        matched_chunk = chunks[idx]
        print(f"#{rank}")
        print(f"[ê±°ë¦¬: {score:.4f}]")
        print(matched_chunk)
        print("â€”" * 40)

        log_entries.append({
            "timestamp": timestamp,
            "question": question,
            "rank": rank,
            "chunk_index": idx,
            "distance": round(float(score), 4),
            "matched_text": matched_chunk.replace("\n", " ")
        })

    save_logs(log_entries)

# CSV ì €ì¥ í•¨ìˆ˜
def save_logs(entries):
    fieldnames = ["timestamp", "question", "rank", "chunk_index", "distance", "matched_text"]
    file_exists = os.path.exists(LOG_PATH)

    with open(LOG_PATH, "a", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        if not file_exists:
            writer.writeheader()
        for row in entries:
            writer.writerow(row)

if __name__ == "__main__":
    question = "GPTê°€ ì™œ ì¤‘ìš”í•œ ê¸°ìˆ ì¸ê°€ìš”?"
    search_similar(question)


