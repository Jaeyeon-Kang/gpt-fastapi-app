from fastapi import FastAPI, Request, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, JSONResponse
from openai import OpenAI
from prompt_template import make_prompt
from datetime import datetime
from dotenv import load_dotenv
from pathlib import Path
import faiss, numpy as np, csv, os
import pandas as pd
from utils.data_loader import load_chunks
import config # ì„¤ì • íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¨ë‹¤. ì´ì œ í•˜ë“œì½”ë”©ì€ ê·¸ë§Œ.

# â”€â”€ í™˜ê²½ ë° í´ë¼ì´ì–¸íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

app = FastAPI()

# ì •ì  íŒŒì¼ ì„œë¹™ ì„¤ì •
app.mount("/static", StaticFiles(directory="static"), name="static")

# CORS ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€: ì´ì œ ë³´ì•ˆì„ ì¡°ê¸ˆ ë” ì‹ ê²½ ì“´ ì„¤ì •ìœ¼ë¡œ.
app.add_middleware(
    CORSMiddleware,
    allow_origins=config.ALLOWED_ORIGINS, # config.pyì— ì •ì˜ëœ ì£¼ì†Œë§Œ í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ---------- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def log_chat(ts, user_input, role, temp, reply):
    os.makedirs(config.LOG_DIR, exist_ok=True)
    path = config.CHAT_LOG_PATH
    new  = not Path(path).exists()
    with open(path, "a", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, ["timestamp", "user_input", "system_role", "temperature", "reply"])
        if new: w.writeheader()
        w.writerow({
            "timestamp": ts, "user_input": user_input,
            "system_role": role, "temperature": temp, "reply": reply
        })

def ensure_faiss_index():
    """index.faiss ê°€ ì—†ê±°ë‚˜ text íŒŒì¼ì´ ìƒˆë¡œ ìˆ˜ì •ëìœ¼ë©´ ìë™ ìƒì„±."""
    idx_path = Path(config.INDEX_PATH)
    txt_path = Path(config.TEXT_PATH)
    if not idx_path.exists() or (txt_path.exists() and txt_path.stat().st_mtime > idx_path.stat().st_mtime):
        print("ğŸ”„ FAISS ì¸ë±ìŠ¤ë¥¼ ë‹¤ì‹œ ë§Œë“œëŠ” ì¤‘... ì ì‹œ ê¸°ë‹¤ë ¤.")
        try:
            from experiments.generate_embedding import build_index
            chunks = load_chunks()
            build_index(chunks)
            print("âœ… index.faiss ìƒì„± ì™„ë£Œ.")
        except Exception as e:
            print(f"âŒ Faiss ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")

def embed_text(text: str):
    try:
        emb = client.embeddings.create(input=text, model=config.EMBED_MODEL).data[0].embedding
        return np.asarray(emb, dtype="float32").reshape(1, -1)
    except Exception as e:
        # OpenAI APIì—ì„œ ì—ëŸ¬ê°€ ë‚˜ë©´, ì„œë²„ê°€ ì£½ëŠ” ëŒ€ì‹  í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì•Œë ¤ì¤€ë‹¤.
        raise HTTPException(status_code=500, detail=f"ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {e}")

# ---------- API ë¼ìš°íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/")
async def read_root():
    """ë£¨íŠ¸ ê²½ë¡œì—ì„œ index.html íŒŒì¼ì„ ì„œë¹™í•œë‹¤."""
    try:
        with open("static/index.html", "r", encoding="utf-8") as f:
            return HTMLResponse(content=f.read())
    except FileNotFoundError:
        # í˜¹ì‹œë¼ë„ index.htmlì´ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ì¹œì ˆí•œ ì•ˆë‚´.
        raise HTTPException(status_code=404, detail="index.html íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

@app.post("/search")
async def search(req: Request):
    """RAG ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  GPT ë‹µë³€ê³¼ ì°¸ì¡° ë¬¸ì„œë¥¼ ë°˜í™˜í•œë‹¤."""
    try:
        body  = await req.json()
        q     = body.get("question", "")
        top_k = int(body.get("top_k", 3))
        temp  = float(body.get("temperature", 0.7))
        sys_p = body.get("system_prompt", "ë‹¤ìŒ ë¬¸ë‹¨ë“¤ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.")

        if not q:
            raise HTTPException(status_code=400, detail="ì§ˆë¬¸ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

        # 1. Retrieval
        vec = embed_text(q)
        index = faiss.read_index(config.INDEX_PATH)
        chunks = load_chunks()
        D, I = index.search(vec, top_k)
        top_chunks = [chunks[i] for i in I[0]]

        # 2. Generation
        ctx = "\n\n".join(top_chunks)
        messages = [
            {"role": "system", "content": sys_p},
            {"role": "user", "content": f"{ctx}\n\nì§ˆë¬¸: {q}"}
        ]
        res = client.chat.completions.create(model=config.CHAT_MODEL, messages=messages, temperature=temp)
        ans = res.choices[0].message.content.strip()

        return {
            "question": q,
            "top_k": top_k,
            "temperature": temp,
            "system_prompt": sys_p,
            "top_chunks": [
                {"rank": r + 1, "text": chunks[i], "distance": float(D[0][r])}
                for r, i in enumerate(I[0])
            ],
            "gpt_answer": ans
        }
    except FileNotFoundError:
        raise HTTPException(status_code=500, detail="Faiss ì¸ë±ìŠ¤ ë˜ëŠ” í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        # ì´ì œ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬ê°€ ë‚˜ë„ ì„œë²„ëŠ” ì£½ì§€ ì•ŠëŠ”ë‹¤.
        return JSONResponse(status_code=500, content={"message": f"ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜: {e}"})

@app.get("/results")
async def get_results():
    """ì‹¤í—˜ ê²°ê³¼ CSV íŒŒì¼ì„ ì½ì–´ JSONìœ¼ë¡œ ë°˜í™˜í•œë‹¤."""
    try:
        results_dir = Path("experiments/results")
        csv_files = sorted(results_dir.glob("grid_search_*.csv"), key=os.path.getmtime, reverse=True)
        if not csv_files:
            raise FileNotFoundError

        latest_csv = csv_files[0]
        df = pd.read_csv(latest_csv)
        
        # ì‹¤ì œ CSV í—¤ë”ì— ë§ê²Œ ì—´ ì´ë¦„ ìˆ˜ì •
        # 'Recall@5' -> 'recall@5'
        # 'F1 Score' -> 'f1'
        # 'Latency(ms)' -> 'latency_ms'
        # 'Cost($)' -> 'cost_cents' (ë‹¨ìœ„ê°€ ì„¼íŠ¸ì´ë¯€ë¡œ ë‹¬ëŸ¬ë¡œ ë³€í™˜ í•„ìš”)
        
        # ì†Œìˆ˜ì  ë‘˜ì§¸ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼í•˜ê³  ë‹¬ëŸ¬ë¡œ ë³€í™˜
        if 'cost_cents' in df.columns:
            df['cost_dollars'] = (df['cost_cents']).round(4)

        # ìƒìœ„ 10ê°œ ê²°ê³¼ ì„ íƒ
        top_10 = df.nlargest(10, ['recall@5', 'f1']).to_dict(orient='records')

        # ì „ì²´ ìš”ì•½ ì •ë³´ ê³„ì‚°
        summary = {
            "total_experiments": len(df),
            "best_recall": df['recall@5'].max(),
            "best_f1": df['f1'].max(),
            "avg_latency_ms": df['latency_ms'].mean(),
            "avg_cost": df['cost_dollars'].mean() if 'cost_dollars' in df.columns else df['cost_cents'].mean(),
            "perfect_scores": len(df[(df['recall@5'] == 1.0) & (df['f1'] == 1.0)])
        }
        
        return {"summary": summary, "top_results": top_10}

    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="ì‹¤í—˜ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except KeyError as e:
        # íŠ¹ì • ì»¬ëŸ¼ì´ ì—†ì„ ë•Œ ë°œìƒí•˜ëŠ” ì—ëŸ¬ë¥¼ ì¢€ ë” ëª…í™•í•˜ê²Œ ì•Œë ¤ì¤€ë‹¤.
        raise HTTPException(status_code=500, detail=f"ê²°ê³¼ íŒŒì¼ì—ì„œ í•„ìš”í•œ ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê²°ê³¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ---------- ì•± ì‹œì‘ ì‹œ ì¸ë±ìŠ¤ í™•ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ensure_faiss_index()
