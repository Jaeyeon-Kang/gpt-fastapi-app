from fastapi import FastAPI, Request, HTTPException, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, JSONResponse
from openai import OpenAI
from prompt_template import make_prompt
from datetime import datetime
from dotenv import load_dotenv
from pathlib import Path
import faiss, numpy as np, csv, os, time
import pandas as pd
from utils.data_loader import load_chunks
import config # ì„¤ì • íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¨ë‹¤. ì´ì œ í•˜ë“œì½”ë”©ì€ ê·¸ë§Œ.
import PyPDF2
from docx import Document
import io

# â”€â”€ í™˜ê²½ ë° í´ë¼ì´ì–¸íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

app = FastAPI()

# ì •ì  íŒŒì¼ ì„œë¹™ ì„¤ì •
app.mount("/static", StaticFiles(directory="static"), name="static")

# CORS ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€: ì´ì œ ë³´ì•ˆì„ ì¡°ê¸ˆ ë” ì‹ ê²½ ì“´ ì„¤ì •ìœ¼ë¡œ.
app.add_middleware(
    CORSMiddleware,
    allow_origins=config.ALLOWED_ORIGINS, # config.pyì— ì •ì˜ëœ ì£¼ì†Œë§Œ í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ---------- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def log_chat(ts, user_input, role, temp, reply):
    os.makedirs(config.LOG_DIR, exist_ok=True)
    path = config.CHAT_LOG_PATH
    new  = not Path(path).exists()
    with open(path, "a", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, ["timestamp", "user_input", "system_role", "temperature", "reply"])
        if new: w.writeheader()
        w.writerow({
            "timestamp": ts, "user_input": user_input,
            "system_role": role, "temperature": temp, "reply": reply
        })

def ensure_faiss_index():
    """index.faiss ê°€ ì—†ê±°ë‚˜ text íŒŒì¼ì´ ìƒˆë¡œ ìˆ˜ì •ëìœ¼ë©´ ìë™ ìƒì„±."""
    idx_path = Path(config.INDEX_PATH)
    txt_path = Path(config.TEXT_PATH)
    if not idx_path.exists() or (txt_path.exists() and txt_path.stat().st_mtime > idx_path.stat().st_mtime):
        print("ğŸ”„ FAISS ì¸ë±ìŠ¤ë¥¼ ë‹¤ì‹œ ë§Œë“œëŠ” ì¤‘... ì ì‹œ ê¸°ë‹¤ë ¤.")
        try:
            from experiments.generate_embedding import build_index
            chunks = load_chunks()
            build_index(chunks)
            print("âœ… index.faiss ìƒì„± ì™„ë£Œ.")
        except Exception as e:
            print(f"âŒ Faiss ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")

def embed_text(text: str):
    try:
        emb = client.embeddings.create(input=text, model=config.EMBED_MODEL).data[0].embedding
        return np.asarray(emb, dtype="float32").reshape(1, -1)
    except Exception as e:
        # OpenAI APIì—ì„œ ì—ëŸ¬ê°€ ë‚˜ë©´, ì„œë²„ê°€ ì£½ëŠ” ëŒ€ì‹  í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì•Œë ¤ì¤€ë‹¤.
        raise HTTPException(status_code=500, detail=f"ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {e}")

# ---------- íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_text_from_file(file: UploadFile) -> str:
    """íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        content = file.file.read()
        
        if file.filename.endswith('.txt'):
            return content.decode('utf-8')
        
        elif file.filename.endswith('.pdf'):
            pdf_reader = PyPDF2.PdfReader(io.BytesIO(content))
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
            return text
        
        elif file.filename.endswith('.docx'):
            doc = Document(io.BytesIO(content))
            text = ""
            for paragraph in doc.paragraphs:
                text += paragraph.text + "\n"
            return text
        
        elif file.filename.endswith('.csv'):
            # CSVë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            csv_text = content.decode('utf-8')
            return csv_text
        
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file.filename}")
            
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

def chunk_text(text: str, chunk_size: int, chunk_overlap: int) -> list:
    """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤."""
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        length_function=len,
        separators=["\n\n", "\n", ". ", " ", ""]
    )
    return text_splitter.split_text(text)

def rebuild_index(chunks: list) -> dict:
    """ìƒˆë¡œìš´ ì²­í¬ë“¤ë¡œ FAISS ì¸ë±ìŠ¤ë¥¼ ì¬êµ¬ì„±í•©ë‹ˆë‹¤."""
    try:
        # ê¸°ì¡´ ì²­í¬ ë¡œë“œ
        existing_chunks = load_chunks()
        
        # ìƒˆ ì²­í¬ ì¶”ê°€
        all_chunks = existing_chunks + chunks
        
        # ì„ë² ë”© ìƒì„±
        print(f"ğŸ”„ {len(all_chunks)}ê°œ ì²­í¬ì˜ ì„ë² ë”©ì„ ìƒì„±í•˜ëŠ” ì¤‘...")
        embeddings = []
        for i, chunk in enumerate(all_chunks):
            if i % 10 == 0:
                print(f"ì§„í–‰ë¥ : {i}/{len(all_chunks)}")
            emb = client.embeddings.create(input=chunk, model=config.EMBED_MODEL).data[0].embedding
            embeddings.append(emb)
        
        embeddings = np.array(embeddings, dtype='float32')
        
        # FAISS ì¸ë±ìŠ¤ ìƒì„±
        dimension = embeddings.shape[1]
        index = faiss.IndexFlatIP(dimension)
        index.add(embeddings)
        
        # ì¸ë±ìŠ¤ ì €ì¥
        faiss.write_index(index, config.INDEX_PATH)
        
        # ìƒˆ ì²­í¬ë“¤ì„ í…ìŠ¤íŠ¸ íŒŒì¼ì— ì¶”ê°€
        with open(config.TEXT_PATH, 'a', encoding='utf-8') as f:
            for chunk in chunks:
                f.write(chunk + '\n')
        
        return {
            "total_chunks": len(all_chunks),
            "new_chunks": len(chunks),
            "index_size_mb": os.path.getsize(config.INDEX_PATH) / (1024 * 1024)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì¸ë±ìŠ¤ ì¬êµ¬ì„± ì˜¤ë¥˜: {str(e)}")

# ---------- API ë¼ìš°íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/")
async def read_root():
    """ë£¨íŠ¸ ê²½ë¡œì—ì„œ index.html íŒŒì¼ì„ ì„œë¹™í•œë‹¤."""
    try:
        with open("static/index.html", "r", encoding="utf-8") as f:
            return HTMLResponse(content=f.read())
    except FileNotFoundError:
        # í˜¹ì‹œë¼ë„ index.htmlì´ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ì¹œì ˆí•œ ì•ˆë‚´.
        raise HTTPException(status_code=404, detail="index.html íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

@app.post("/search")
async def search(req: Request):
    """RAG ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  GPT ë‹µë³€ê³¼ ì°¸ì¡° ë¬¸ì„œë¥¼ ë°˜í™˜í•œë‹¤."""
    try:
        body  = await req.json()
        q     = body.get("question", "")
        top_k = int(body.get("top_k", 3))
        temp  = float(body.get("temperature", 0.7))
        sys_p = body.get("system_prompt", "ë‹¤ìŒ ë¬¸ë‹¨ë“¤ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.")

        if not q:
            raise HTTPException(status_code=400, detail="ì§ˆë¬¸ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

        # 1. Retrieval
        vec = embed_text(q)
        index = faiss.read_index(config.INDEX_PATH)
        chunks = load_chunks()
        D, I = index.search(vec, top_k)
        top_chunks = [chunks[i] for i in I[0]]

        # 2. Generation
        ctx = "\n\n".join(top_chunks)
        messages = [
            {"role": "system", "content": sys_p},
            {"role": "user", "content": f"{ctx}\n\nì§ˆë¬¸: {q}"}
        ]
        res = client.chat.completions.create(model=config.CHAT_MODEL, messages=messages, temperature=temp)
        ans = res.choices[0].message.content.strip()

        return {
            "question": q,
            "top_k": top_k,
            "temperature": temp,
            "system_prompt": sys_p,
            "top_chunks": [
                {"rank": r + 1, "text": chunks[i], "distance": float(D[0][r])}
                for r, i in enumerate(I[0])
            ],
            "gpt_answer": ans
        }
    except FileNotFoundError:
        raise HTTPException(status_code=500, detail="Faiss ì¸ë±ìŠ¤ ë˜ëŠ” í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        # ì´ì œ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬ê°€ ë‚˜ë„ ì„œë²„ëŠ” ì£½ì§€ ì•ŠëŠ”ë‹¤.
        return JSONResponse(status_code=500, content={"message": f"ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜: {e}"})

@app.post("/upload")
async def upload_files(
    files: list[UploadFile] = File(...),
    chunk_size: int = Form(512),
    chunk_overlap: int = Form(100)
):
    """íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  RAG ì‹œìŠ¤í…œì— ì¶”ê°€í•©ë‹ˆë‹¤."""
    try:
        start_time = time.time()
        
        if not files:
            raise HTTPException(status_code=400, detail="ì—…ë¡œë“œí•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        all_chunks = []
        processed_files = 0
        
        for file in files:
            if not file.filename:
                continue
                
            # íŒŒì¼ í¬ê¸° ì œí•œ (10MB)
            if file.size > 10 * 1024 * 1024:
                raise HTTPException(status_code=400, detail=f"íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤: {file.filename}")
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text = extract_text_from_file(file)
            
            # ì²­í‚¹
            chunks = chunk_text(text, chunk_size, chunk_overlap)
            all_chunks.extend(chunks)
            processed_files += 1
            
            print(f"âœ… {file.filename} ì²˜ë¦¬ ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬ ìƒì„±")
        
        if not all_chunks:
            raise HTTPException(status_code=400, detail="ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì¸ë±ìŠ¤ ì¬êµ¬ì„±
        index_info = rebuild_index(all_chunks)
        
        processing_time = time.time() - start_time
        
        return {
            "files_processed": processed_files,
            "chunks_created": len(all_chunks),
            "processing_time": round(processing_time, 2),
            "index_size": round(index_info["index_size_mb"], 2),
            "total_chunks": index_info["total_chunks"]
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì—…ë¡œë“œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.post("/add-text")
async def add_text_document(
    title: str = Form(...),
    content: str = Form(...),
    chunk_size: int = Form(512),
    chunk_overlap: int = Form(100)
):
    """í…ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ì…ë ¥í•˜ì—¬ RAG ì‹œìŠ¤í…œì— ì¶”ê°€í•©ë‹ˆë‹¤."""
    try:
        start_time = time.time()
        
        # ì…ë ¥ ê²€ì¦
        if not title or not title.strip():
            raise HTTPException(status_code=400, detail="ë¬¸ì„œ ì œëª©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        if not content or not content.strip():
            raise HTTPException(status_code=400, detail="ë¬¸ì„œ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        # ì œëª© ê¸¸ì´ ì œí•œ
        if len(title.strip()) > 200:
            raise HTTPException(status_code=400, detail="ë¬¸ì„œ ì œëª©ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. 200ì ì´í•˜ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (1MB)
        content_bytes = content.encode('utf-8')
        if len(content_bytes) > 1024 * 1024:
            raise HTTPException(status_code=400, detail="í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤. 1MB ì´í•˜ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        # ì²­í‚¹ íŒŒë¼ë¯¸í„° ê²€ì¦
        if chunk_size < 100 or chunk_size > 2000:
            raise HTTPException(status_code=400, detail="ì²­í¬ í¬ê¸°ëŠ” 100-2000 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.")
        
        if chunk_overlap < 0 or chunk_overlap >= chunk_size:
            raise HTTPException(status_code=400, detail="ì²­í¬ ê²¹ì¹¨ì€ 0 ì´ìƒì´ê³  ì²­í¬ í¬ê¸°ë³´ë‹¤ ì‘ì•„ì•¼ í•©ë‹ˆë‹¤.")
        
        # ì²­í‚¹
        chunks = chunk_text(content, chunk_size, chunk_overlap)
        
        if not chunks:
            raise HTTPException(status_code=400, detail="ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì¸ë±ìŠ¤ ì¬êµ¬ì„±
        index_info = rebuild_index(chunks)
        
        processing_time = time.time() - start_time
        
        # ë¡œê¹… ê°œì„ 
        print(f"âœ… í…ìŠ¤íŠ¸ ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ:")
        print(f"   - ì œëª©: {title}")
        print(f"   - ì²­í¬ ìˆ˜: {len(chunks)}ê°œ")
        print(f"   - ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
        print(f"   - ì¸ë±ìŠ¤ í¬ê¸°: {index_info['index_size_mb']:.2f}MB")
        
        return {
            "title": title,
            "chunks_created": len(chunks),
            "processing_time": round(processing_time, 2),
            "index_size": round(index_info["index_size_mb"], 2),
            "total_chunks": index_info["total_chunks"],
            "content_size_bytes": len(content_bytes)
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.get("/results")
async def get_results():
    """ì‹¤í—˜ ê²°ê³¼ CSV íŒŒì¼ì„ ì½ì–´ JSONìœ¼ë¡œ ë°˜í™˜í•œë‹¤."""
    try:
        results_dir = Path("experiments/results")
        csv_files = sorted(results_dir.glob("grid_search_*.csv"), key=os.path.getmtime, reverse=True)
        if not csv_files:
            raise FileNotFoundError

        latest_csv = csv_files[0]
        df = pd.read_csv(latest_csv)
        
        if 'cost_cents' in df.columns:
            df['cost_dollars'] = (df['cost_cents']).round(4)

        top_10 = df.nlargest(10, ['recall@5', 'f1']).to_dict(orient='records')

        summary = {
            "total_experiments": len(df),
            "best_recall": df['recall@5'].max(),
            "best_f1": df['f1'].max(),
            "avg_latency_ms": df['latency_ms'].mean(),
            "avg_cost": df['cost_dollars'].mean() if 'cost_dollars' in df.columns else df['cost_cents'].mean(),
            "perfect_scores": len(df[(df['recall@5'] == 1.0) & (df['f1'] == 1.0)])
        }
        
        # ë¸Œë¼ìš°ì €ê°€ ì‘ë‹µì„ ìºì‹±í•˜ì§€ ì•Šë„ë¡ í—¤ë” ì¶”ê°€
        headers = {"Cache-Control": "no-cache, no-store, must-revalidate"}
        return JSONResponse(content={"summary": summary, "top_results": top_10}, headers=headers)

    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="ì‹¤í—˜ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except KeyError as e:
        raise HTTPException(status_code=500, detail=f"ê²°ê³¼ íŒŒì¼ì—ì„œ í•„ìš”í•œ ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê²°ê³¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ---------- ì•± ì‹œì‘ ì‹œ ì¸ë±ìŠ¤ í™•ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ensure_faiss_index()

# ---------- ì„œë²„ ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
